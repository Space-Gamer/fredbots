{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# DQN Agent class\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_shape, num_actions):\n",
    "        self.state_shape = state_shape\n",
    "        self.num_actions = num_actions\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential([\n",
    "            Dense(64, activation='relu', input_shape=(self.state_shape,)),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(self.num_actions)  # Output layer with one node for each action\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    def select_action(self, state, epsilon=0.1):\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.randint(self.num_actions)\n",
    "        else:\n",
    "            state = np.expand_dims(state, axis=0)\n",
    "            q_values = self.model.predict(state)\n",
    "            return np.argmax(q_values)\n",
    "\n",
    "    def train(self, states, target_Q):\n",
    "        self.model.fit(states, target_Q, verbose=0)\n",
    "\n",
    "# Helper function to sample a mini-batch from the replay buffer\n",
    "def sample_mini_batch_from_replay_buffer(replay_buffer, batch_size):\n",
    "    mini_batch_indices = np.random.randint(len(replay_buffer), size=batch_size)\n",
    "    return [replay_buffer[i] for i in mini_batch_indices]\n",
    "\n",
    "# Environment setup\n",
    "def get_reward(current_state, goal_state):\n",
    "    # Implement your reward function based on the current and goal states\n",
    "    # For example, you can use negative distance as the reward\n",
    "    distance = np.linalg.norm(current_state - goal_state)\n",
    "    return -distance\n",
    "\n",
    "# DQN hyperparameters\n",
    "state_shape = 4  # (x_current, y_current, x_goal, y_goal)\n",
    "num_actions = 4  # For example, 4 actions: up, down, left, right\n",
    "batch_size = 32\n",
    "num_episodes = 1000\n",
    "discount_factor = 0.99\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = 0.1\n",
    "epsilon_decay_steps = 1000\n",
    "\n",
    "# Initialize the DQN agent\n",
    "agent = DQNAgent(state_shape, num_actions)\n",
    "\n",
    "# Replay buffer to store experiences\n",
    "replay_buffer = []\n",
    "\n",
    "# Training loop\n",
    "epsilon = epsilon_start\n",
    "for episode in range(num_episodes):\n",
    "    current_state = np.random.rand(2)  # Initialize the current state randomly\n",
    "    goal_state = np.random.rand(2)     # Initialize the goal state randomly\n",
    "\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Epsilon-greedy action selection\n",
    "        action = agent.select_action(np.concatenate([current_state, goal_state]), epsilon)\n",
    "\n",
    "        # Simulate the action and observe the next state and reward\n",
    "        next_state = current_state.copy()  # For simplicity, we assume the agent moves by one step\n",
    "        if action == 0:\n",
    "            next_state[1] += 1  # Move up\n",
    "        elif action == 1:\n",
    "            next_state[1] -= 1  # Move down\n",
    "        elif action == 2:\n",
    "            next_state[0] -= 1  # Move left\n",
    "        else:\n",
    "            next_state[0] += 1  # Move right\n",
    "\n",
    "        reward = get_reward(current_state, goal_state)\n",
    "\n",
    "        # Store the experience in the replay buffer\n",
    "        replay_buffer.append({\n",
    "            'state': np.concatenate([current_state, goal_state]),\n",
    "            'action': action,\n",
    "            'reward': reward,\n",
    "            'next_state': np.concatenate([next_state, goal_state]),\n",
    "            'done': done\n",
    "        })\n",
    "\n",
    "        total_reward += reward\n",
    "        current_state = next_state\n",
    "\n",
    "        if len(replay_buffer) >= batch_size:\n",
    "            # Sample a mini-batch from the replay buffer\n",
    "            mini_batch = sample_mini_batch_from_replay_buffer(replay_buffer, batch_size)\n",
    "\n",
    "            states = np.array([experience['state'] for experience in mini_batch])\n",
    "            actions = np.array([experience['action'] for experience in mini_batch])\n",
    "            rewards = np.array([experience['reward'] for experience in mini_batch])\n",
    "            next_states = np.array([experience['next_state'] for experience in mini_batch])\n",
    "            dones = np.array([experience['done'] for experience in mini_batch])\n",
    "\n",
    "            # Compute the target Q-values based on the Bellman equation\n",
    "            target_Q = rewards + discount_factor * np.amax(agent.model.predict(next_states), axis=1) * (1 - dones)\n",
    "\n",
    "            # Create a mask to zero out the Q-values for terminal states\n",
    "            target_Q *= (1 - dones)\n",
    "\n",
    "            # Train the DQN agent with the mini-batch\n",
    "            agent.train(states, target_Q)\n",
    "\n",
    "    # Decay epsilon for epsilon-greedy exploration\n",
    "    epsilon = max(epsilon_end, epsilon_start - episode / epsilon_decay_steps)\n",
    "\n",
    "    print(f\"Episode {episode}: Total Reward = {total_reward}\")\n",
    "\n",
    "# After training, you can use the trained model for making predictions:\n",
    "# goal_state = np.array([goal_x, goal_y])  # Set the goal state for testing\n",
    "# current_state = np.array([start_x, start_y])  # Set the current state for testing\n",
    "# action = agent.select_action(np.concatenate([current_state, goal_state]), epsilon=0.0)\n",
    "# print(f\"Selected Action: {action}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-20 11:52:02.685156: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-20 11:52:03.088855: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-20 11:52:03.093037: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-20 11:52:04.959305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN Agent class\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_shape, num_actions):\n",
    "        self.state_shape = state_shape\n",
    "        self.num_actions = num_actions\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        model = Sequential([\n",
    "            Dense(64, activation='relu', input_shape=(self.state_shape,)),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dense(self.num_actions)  # Output layer with one node for each action\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                      loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    def select_action(self, state, epsilon=0.1):\n",
    "        if np.random.rand() < epsilon:\n",
    "            return np.random.randint(self.num_actions)\n",
    "        else:\n",
    "            state = np.expand_dims(state, axis=0)\n",
    "            q_values = self.model.predict(state)\n",
    "            return np.argmax(q_values)\n",
    "\n",
    "    def train(self, states, target_Q):\n",
    "        self.model.fit(states, target_Q, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to sample a mini-batch from the replay buffer\n",
    "def sample_mini_batch_from_replay_buffer(replay_buffer, batch_size):\n",
    "    mini_batch_indices = np.random.randint(len(replay_buffer), size=batch_size)\n",
    "    return [replay_buffer[i] for i in mini_batch_indices]\n",
    "\n",
    "# Environment setup\n",
    "def get_reward(current_state, goal_state):\n",
    "    # Implement your reward function based on the current and goal states\n",
    "    # For example, you can use negative distance as the reward\n",
    "    distance = np.linalg.norm(current_state - goal_state)\n",
    "    return -distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DQN hyperparameters\n",
    "state_shape = 4  # (x_current, y_current, x_goal, y_goal)\n",
    "num_actions = 4  # For example, 4 actions: up, down, left, right\n",
    "batch_size = 32\n",
    "num_episodes = 10\n",
    "discount_factor = 0.99\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = 0.1\n",
    "epsilon_decay_steps = 1000\n",
    "\n",
    "# Initialize the DQN agent\n",
    "agent = DQNAgent(state_shape, num_actions)\n",
    "\n",
    "# Replay buffer to store experiences\n",
    "replay_buffer = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1-dones:  [ -4.35691161  -5.74569641  -3.78709321  -4.82001159  -1.71241617\n",
      "  -6.39225821  -6.26684928  -8.83537026 -10.83245268  -4.82001159\n",
      "  -6.26684928 -12.44371289  -8.83537026  -6.43353659 -12.44371289\n",
      "  -9.41819356  -9.3382988   -9.41819356  -9.3382988   -4.82001159\n",
      " -12.19023078  -4.35691161  -6.43353659 -10.70312753  -6.43353659\n",
      " -11.96068226  -8.01967294 -11.5831928  -11.07157232  -4.1011998\n",
      "  -9.25412193  -8.92970202]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1-dones:  [ -4.1011998  -10.78017974  -3.28533841 -10.02754388  -9.41819356\n",
      " -11.96068226 -12.48619483  -6.91730974 -12.44371289  -1.71241617\n",
      "  -9.10481059  -4.67973704 -10.32671895  -9.3382988   -4.1011998\n",
      "  -9.92343177 -12.44371289  -7.29610679  -9.92343177  -9.41819356\n",
      " -11.96068226  -1.71241617  -7.56645329  -9.92343177  -9.41819356\n",
      "  -8.01967294 -12.19023078 -11.96068226  -9.3382988   -8.11578082\n",
      "  -4.35691137  -3.78709321]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1-dones:  [-10.83245268  -8.01967294  -5.01213156  -9.3382988  -11.07157232\n",
      "  -8.83537026  -6.91730974  -8.88507914  -9.81042679  -8.83537026\n",
      " -11.5831928   -9.41819356  -9.958474    -6.26684928 -11.85306575\n",
      "  -4.35691161  -6.26684928  -8.01967294  -7.29610679 -11.96068226\n",
      " -10.45626774  -8.01967294  -4.35691161  -9.3382988   -3.26401339\n",
      "  -8.83537026  -9.36620082  -9.92343177  -3.78709321  -8.01967294\n",
      "  -1.264586    -6.9173095 ]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1-dones:  [ -1.26458606  -3.78709321 -10.78017974  -7.29610679  -8.01967294\n",
      "  -6.91730974 -11.74627596  -4.1011998   -8.11578082 -11.96068226\n",
      " -10.21463599  -8.92970202  -9.3382988  -11.10171285  -7.29610679\n",
      "  -8.11578082  -8.3621067   -9.41819356  -3.28533841  -9.25412217\n",
      "  -9.41819356  -6.39225821 -10.70312753  -9.10481059 -11.10171285\n",
      "  -9.10481059  -9.41819356  -5.85480241  -4.35691161  -9.3382988\n",
      " -10.70312776  -9.81042727]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1-dones:  [ -6.26684928 -12.44371289  -1.26458606 -12.44371289  -8.5070493\n",
      "  -8.83537026  -2.14868783 -10.83245268  -2.19874094 -10.78017974\n",
      "  -9.80579076  -6.91730974 -10.83245268  -8.00281643  -8.5070493\n",
      "  -6.09179024  -8.88507914  -8.88507914  -4.35691161  -5.74569641\n",
      " -11.5831928   -9.92343177 -12.19023078 -11.5831928   -9.81042679\n",
      "  -8.92970202 -11.5831928   -8.00281643 -12.19023078  -3.78709321\n",
      " -12.19023102 -10.78017998]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1-dones:  [ -2.26967535  -9.41819356  -8.11578082 -12.97884258  -5.85394455\n",
      "  -8.5070493   -3.78709321  -3.26401339  -4.24191054  -4.67973704\n",
      "  -4.1011998   -4.1011998   -9.92343177 -12.48619483  -5.33384584\n",
      "  -6.26684928  -6.91730974  -9.10481059  -4.24191054  -9.36620082\n",
      "  -7.56645329  -4.2605197   -3.78709321  -5.85480241 -11.74627596\n",
      "  -4.35691161  -9.3382988   -1.71241617  -3.78709321  -9.80579076\n",
      "  -5.25945637 -11.96068226]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1-dones:  [ -5.85480241 -12.48619483  -6.39225821  -6.09179024  -3.26401339\n",
      "  -3.78709321  -2.19874094  -8.11578082  -4.67973704  -4.2605197\n",
      "  -6.91730974  -9.3382988   -9.36620082 -11.85306575  -9.41819356\n",
      "  -4.35691161  -2.14868783  -4.24191054  -9.92343177  -4.82001159\n",
      "  -9.3382988   -9.36620082  -5.74569641 -10.02754388  -8.3621067\n",
      "  -3.26401339 -10.45626774  -9.41819356  -7.56645329  -1.71241617\n",
      "  -8.00281643  -5.85394432]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1-dones:  [ -1.26458606  -3.26401339 -11.85306575 -12.44371289  -6.39225821\n",
      "  -3.55056204  -9.3382988  -10.78017974  -5.74569641 -11.96068226\n",
      "  -2.19874094 -12.97884258  -5.85394455  -8.5070493   -8.88507914\n",
      "  -5.85480241  -8.01967294  -9.41819356  -6.91730974  -6.91730974\n",
      " -10.32671895  -4.35691161  -2.14868783 -11.07157232  -9.41819356\n",
      " -11.96068226  -9.41819356  -4.2605197  -11.85306575  -8.83537026\n",
      "  -7.56645353  -2.2696754 ]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1-dones:  [ -9.92343177  -9.41819356  -1.26458606  -1.71241617  -4.35691161\n",
      "  -2.14868783 -10.83245268  -9.10481059  -6.43353659 -11.5831928\n",
      "  -9.80579076 -11.85306575 -10.21463599  -9.3382988   -5.74569641\n",
      "  -1.71241617 -12.19023078  -8.92970202  -5.33384584 -10.02754388\n",
      "  -2.14868783  -6.91730974  -5.25945637  -9.80579076  -8.3621067\n",
      "  -7.56645329  -4.24191054  -4.35691161 -12.44371289 -11.74627596\n",
      "  -9.36620035  -9.80579076]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1-dones:  [ -5.85394455  -9.36620082  -4.1011998   -9.958474    -9.10481059\n",
      " -10.32671895  -4.24191054 -11.07157232  -9.36620082  -3.78709321\n",
      " -12.44371289  -6.26684928 -11.10171285  -5.01213156  -8.11578082\n",
      " -11.07157232  -5.74569641 -11.5831928   -8.01967294 -11.5831928\n",
      "  -8.92970202  -1.26458606  -9.958474    -3.98770153 -12.97884258\n",
      "  -6.39225821  -9.80579076  -3.98770153  -2.26967535 -11.85306575\n",
      "  -9.36620035  -3.5505621 ]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1-dones:  [ -6.39225821  -7.29610679  -9.36620082  -4.82001159  -5.01213156\n",
      "  -6.39225821 -12.97884258  -8.5070493   -9.10481059  -5.01213156\n",
      "  -4.24191054 -10.32671895  -9.80579076  -8.01967294 -11.5831928\n",
      "  -9.10481059  -5.33384584  -8.11578082  -5.85394455  -1.71241617\n",
      "  -9.3382988   -7.29610679  -6.43353659 -12.44371289  -2.26967535\n",
      "  -2.19874094  -6.91730974  -3.98770153  -3.78709321  -9.3382988\n",
      " -11.96068226 -12.97884258]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1-dones:  [ -6.09179024  -4.35691161  -8.5070493   -9.958474    -3.78709321\n",
      "  -6.09179024  -4.2605197   -3.26401339 -10.78017974  -6.39225821\n",
      "  -4.2605197   -3.55056204  -5.74569641  -4.24191054 -12.44371289\n",
      "  -4.35691161  -9.41819356  -9.41819356  -9.10481059  -8.01967294\n",
      " -10.02754388  -4.24191054  -9.36620082  -9.10481059 -11.5831928\n",
      "  -4.1011998   -8.01967294  -9.41819356 -12.48619483  -9.41819356\n",
      " -10.70312776  -6.43353659]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1-dones:  [ -4.2605197   -9.36620082  -4.82001159  -8.92970202  -4.2605197\n",
      " -10.02754388  -8.83537026 -12.48619483  -3.78709321  -4.35691161\n",
      "  -8.11578082  -9.92343177 -11.96068226 -10.83245268 -10.83245268\n",
      "  -9.36620082 -11.5831928   -9.10481059 -11.96068226 -12.19023078\n",
      "  -9.41819356 -12.48619483  -3.28533841 -12.44371289  -4.35691161\n",
      "  -8.00281643  -3.33578656 -10.21463599  -3.98770153  -8.11578082\n",
      " -10.70312776 -10.45626774]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1-dones:  [ -4.67973704 -11.10171285 -11.96068226  -9.92343177  -4.35691161\n",
      "  -8.92970202  -9.80579076  -3.28533841 -10.70312753  -5.74569641\n",
      " -11.74627596  -8.01967294  -9.10481059  -9.10481059  -4.84286142\n",
      "  -9.958474   -12.48619483 -10.02754388  -5.01213156 -10.21463599\n",
      " -11.96068226  -9.958474    -9.41819356  -1.26458606  -9.3382988\n",
      " -11.85306575  -5.85480241  -8.5070493  -10.45626774  -3.78709321\n",
      " -11.85306575  -9.4181938 ]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1-dones:  [ -9.80579076  -6.09179024  -8.83537026  -9.81042679  -6.43353659\n",
      " -11.10171285  -4.9415432   -9.81042679  -3.55056204  -3.78709321\n",
      " -11.07157232  -1.71241617  -9.36620082  -6.91730974 -10.02754388\n",
      "  -9.92343177  -4.10339946  -6.09179024 -12.97884258  -8.5070493\n",
      "  -1.71241617 -10.45626774 -10.83245268  -9.958474   -12.97884258\n",
      "  -8.3621067   -9.10481059  -9.36620082  -6.43353659  -5.01213156\n",
      "  -9.95847424  -2.14868771]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1-dones:  [-11.74627596  -8.5070493   -7.29610679 -10.78017974 -12.48619483\n",
      " -10.70312753  -9.41819356  -3.98770153 -12.44371289  -4.84286142\n",
      "  -4.1011998   -9.41819356  -5.25945637  -9.41819356  -8.5070493\n",
      " -12.44371289 -10.21463599 -11.5831928  -11.07157232  -3.26401339\n",
      "  -4.2605197  -12.48619483  -6.43353659 -11.5831928  -10.02754388\n",
      "  -6.91730974 -11.85306575 -11.5831928   -5.33384584 -11.96068226\n",
      "  -9.10481035  -3.26401339]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1-dones:  [ -8.83537026  -9.25412217  -2.19874094  -7.56645329  -4.2605197\n",
      " -10.83245268  -8.01967294  -6.82930451 -11.10171285  -9.36620082\n",
      " -11.85306575  -4.84286142  -9.10481059  -5.85480241  -5.33384584\n",
      "  -8.88507914  -8.01967294  -9.10481059  -9.41819356  -9.10481059\n",
      "  -4.2605197  -12.97884258  -8.92970202  -2.19874094  -5.85394455\n",
      " -11.74627596  -6.09179024  -9.958474    -4.9415432  -11.10171285\n",
      "  -2.14868771  -9.4181938 ]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1-dones:  [ -4.35691161 -11.74627596  -6.82930451 -12.44371289  -9.36620082\n",
      "  -5.01213156  -4.1011998   -9.41819356  -9.41819356  -5.85480241\n",
      "  -6.39225821  -8.11578082  -4.84286142  -8.11578082 -12.44371289\n",
      "  -4.9415432   -8.83537026 -10.45626774 -10.21463599  -4.84286142\n",
      "  -8.83537026 -10.70312753 -12.44371289 -10.45626774  -9.10481059\n",
      " -11.85306575 -11.96068226  -8.01967294  -4.24191054  -3.55056204\n",
      "  -4.84286148  -8.88507938]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1-dones:  [ -9.958474    -3.84782821  -3.84782821  -1.26458606  -3.26401339\n",
      "  -9.41819356 -11.96068226  -9.10481059 -12.44371289  -4.84286142\n",
      "  -9.958474   -11.07157232  -3.78709321  -5.85394455  -5.25945637\n",
      " -11.85306575 -11.85306575  -8.11578082  -6.91730974 -10.32671895\n",
      "  -4.82001159  -7.29610679  -4.84286142  -9.92343177  -9.81042679\n",
      "  -3.33578656 -12.19023078  -5.33384584  -9.41819356  -5.25945637\n",
      " -11.07157232  -3.33578662]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1-dones:  [ -5.93351669 -11.85306575  -8.5070493   -9.25412217  -9.80579076\n",
      "  -1.26458606  -4.1011998   -3.55056204  -5.85394455 -10.32671895\n",
      "  -4.10339946  -4.67973704  -8.80016855 -10.21463599  -8.03150873\n",
      " -10.70312753  -5.93351669  -9.3382988   -6.82930451 -11.96068226\n",
      "  -4.24191054  -2.19874094  -8.3621067   -4.24191054  -3.84782821\n",
      "  -5.01213156  -3.84782821  -8.00281643  -2.26967535  -4.1011998\n",
      "  -8.00281643  -5.33384584]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1-dones:  [ -3.28533841  -3.28533841 -11.96068226  -8.00281643 -12.44371289\n",
      "  -3.84782821  -4.67973704  -9.10481059  -4.9415432   -9.41819356\n",
      "  -3.78709321  -9.10481059  -8.88507914  -8.0479624  -10.02754388\n",
      "  -9.10481059  -4.35691161  -2.14868783  -8.01967294 -11.85306575\n",
      "  -6.09179024  -9.10481059  -4.67973704  -2.26967535  -5.33384584\n",
      "  -4.10339946  -6.39225821 -12.44371289  -6.43353659  -8.0479624\n",
      "  -3.78709321  -6.9173095 ]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1-dones:  [ -3.78709321  -1.71241617  -2.26967535  -3.55056204  -3.78709321\n",
      " -12.97884258 -10.02754388  -5.74569641  -3.33578656  -8.00281643\n",
      "  -3.84782821  -6.26684928  -4.82001159  -6.82930451  -9.958474\n",
      "  -4.10339946  -9.3382988   -9.36620082  -9.92343177  -3.78709321\n",
      " -12.97884258  -8.03150873 -12.97884258  -5.85394455  -3.28533841\n",
      "  -8.83537026  -9.36620082  -3.28533841 -11.5831928   -8.80016855\n",
      " -11.74627596  -4.10339951]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1-dones:  [ -4.35691161 -11.85306575  -8.83537026  -6.91730974  -9.41819356\n",
      " -12.19023078  -9.41819356  -4.82001159  -9.21590195 -11.96068226\n",
      "  -3.98770153 -10.83245268 -10.45626774  -4.82001159  -9.3382988\n",
      "  -5.93351669 -10.45626774  -9.10481059  -9.21590195  -9.10481059\n",
      "  -9.25412217  -4.1011998   -8.01967294  -8.92970202  -8.01827595\n",
      "  -8.01967294 -10.78017974  -5.93351669  -9.10481059 -10.45626774\n",
      "  -9.36620035  -2.2696754 ]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1-dones:  [-12.44371289  -5.25945637 -12.19023078  -9.36620082 -11.96068226\n",
      " -12.48619483  -8.0479624   -9.41819356 -12.48619483 -12.97884258\n",
      "  -7.29610679  -9.3382988   -3.26401339  -8.2146556  -10.21463599\n",
      "  -6.91730974  -9.41819356  -6.09179024  -3.33578656  -9.41819356\n",
      "  -6.98953969  -3.84782821  -8.3621067   -4.2605197  -10.45626774\n",
      "  -9.25412217  -5.33384584  -6.39225821  -8.01967294 -10.45626774\n",
      "  -4.24191072  -5.85394432]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1-dones:  [ -8.01827595 -12.97884258  -2.26967535  -8.92970202  -8.88507914\n",
      " -12.48619483  -8.83537026  -8.01827595  -9.958474    -9.10481059\n",
      "  -9.92343177  -8.01967294  -8.11578082  -9.92343177  -8.62654306\n",
      " -12.44371289  -4.2605197   -9.41819356  -6.09179024  -9.36620082\n",
      "  -4.67973704  -3.98770153 -10.45626774  -3.55056204  -4.82001159\n",
      "  -5.01213156  -4.1011998   -6.39225821  -8.01827595  -4.2605197\n",
      "  -6.26684904  -5.74569641]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1-dones:  [ -6.39225821  -6.26684928  -8.80016855  -8.83537026  -4.84286142\n",
      "  -5.85480241 -11.10171285  -9.80579076 -11.74627596  -9.958474\n",
      "  -8.80016855  -9.80579076  -9.10481059  -3.55056204  -3.33578656\n",
      " -11.07157232 -12.97884258 -12.48619483 -11.5831928   -9.25412217\n",
      "  -8.2146556  -11.96068226 -11.10171285  -5.33384584 -11.85306575\n",
      "  -2.26967535  -2.19874094  -4.9415432   -9.21590195  -4.84286142\n",
      "  -4.10339951  -4.35691137]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1-dones:  [ -5.85394455  -6.91730974  -4.1011998   -9.41819356  -8.2146556\n",
      "  -5.33384584  -9.25412217  -3.55056204  -3.84782821  -9.92343177\n",
      " -11.07157232 -11.96068226  -8.92970202  -9.80579076  -6.43353659\n",
      "  -5.01213156 -10.21463599 -11.5831928   -8.62654306  -8.00281643\n",
      "  -4.10339946  -8.01967294 -11.96068226  -8.80016855  -8.01827595\n",
      "  -9.10481059  -9.14503123  -4.82001159  -8.2146556   -3.55056204\n",
      " -10.70312776 -11.10171285]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1-dones:  [ -4.2605197   -9.10481059  -3.55056204  -1.26458606  -8.2146556\n",
      " -10.02754388  -5.74569641  -3.28533841 -12.44371289  -4.82001159\n",
      " -10.3755177   -5.85480241 -11.5831928   -4.82001159 -11.85306575\n",
      " -12.97884258  -9.92343177  -4.10339946 -11.96068226  -3.33578656\n",
      "  -3.33578656  -5.85480241  -8.62654306  -9.41819356  -8.88507914\n",
      "  -8.80016855  -6.43353659 -10.83245268  -8.00281643  -9.25412217\n",
      " -12.48619483  -4.9415432 ]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1-dones:  [-10.02754388  -3.78709321 -11.96068226  -6.39225821  -8.03150873\n",
      "  -3.84782821  -4.1011998   -9.92343177 -11.07157232 -10.83245268\n",
      "  -8.00281643  -7.56645329  -8.0479624   -5.74569641  -2.14868783\n",
      "  -9.14503123 -10.45626774 -11.5831928  -10.00958411  -5.25945637\n",
      " -11.96068226  -3.55056204  -4.84286142  -2.19874094  -9.41819356\n",
      " -10.00958411  -1.71241617  -9.81042679  -8.62654306 -10.02754388\n",
      "  -3.5505621   -5.85394432]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1-dones:  [-12.44371289  -8.01967294  -9.92343177  -5.85394455 -12.44371289\n",
      " -11.07157232  -9.41819356  -3.26401339  -4.2605197   -9.10481059\n",
      "  -9.25412217 -10.78017974  -1.71241617 -11.85306575  -6.98953969\n",
      "  -7.29610679  -9.92343177 -10.73736446  -9.92343177  -3.28533841\n",
      " -10.00958411  -4.35691161  -2.26967535  -8.2146556   -9.41819356\n",
      "  -2.14868783  -3.98770153  -4.1011998   -8.01967294 -11.10171285\n",
      "  -1.71241623  -6.39225821]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1-dones:  [ -1.26458606 -11.96068226  -9.14503123 -11.10171285  -8.83537026\n",
      "  -1.26458606  -4.9415432   -8.01827595  -9.14503123  -5.93351669\n",
      "  -2.26967535  -8.2146556   -4.35691161  -5.85394455  -8.00281643\n",
      "  -7.29610679 -12.97884258  -8.11578082  -6.82930451 -11.5831928\n",
      "  -9.80579076  -4.35691161  -9.21590195  -6.39225821  -8.01967294\n",
      " -11.5831928  -11.96068226  -3.84782821  -4.24191054 -12.19023078\n",
      "  -5.25945637  -6.26684904]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1-dones:  [ -9.958474    -9.36620082 -12.44371289 -10.78017974  -8.80016855\n",
      "  -3.33578656 -11.5831928   -2.19874094 -11.85306575  -8.88507914\n",
      "  -4.67973704 -12.19023078  -8.01827595  -9.958474    -8.80016855\n",
      "  -9.41819356 -12.44371289  -5.74569641  -6.09179024  -8.62654306\n",
      " -11.5831928  -11.5831928  -11.74627596  -6.82930451  -9.21590195\n",
      " -10.21463599 -11.85306575 -10.00958411 -11.5831928   -5.33384584\n",
      "  -5.85480193  -8.80016855]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1-dones:  [-10.70312753  -3.98770153  -4.35691161  -3.55056204  -4.10339946\n",
      "  -3.33578656 -11.07157232 -10.45626774  -4.84286142 -10.3755177\n",
      "  -3.84782821  -1.26458606  -5.33384584  -3.84782821  -9.3382988\n",
      "  -8.92970202  -9.3382988   -8.62654306 -11.10171285  -9.25412217\n",
      " -11.74627596 -10.45626774 -12.97884258  -5.25945637 -11.07157232\n",
      "  -9.958474    -9.14503123 -10.3755177   -4.82001159  -3.26401339\n",
      "  -4.1011998   -8.01827595]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1-dones:  [ -3.78709321 -11.5831928  -10.02754388  -6.82930451  -5.01213156\n",
      " -11.96068226  -5.74569641 -11.5831928   -3.84782821 -10.3755177\n",
      " -11.74627596  -6.26684928  -9.958474    -6.09179024  -6.82930451\n",
      "  -8.80016855  -9.25412217  -1.26458606  -8.83537026  -5.74569641\n",
      "  -3.33578656 -10.45626774  -3.78709321  -9.3382988   -1.71241617\n",
      "  -4.1011998  -12.97884258 -10.70312753  -8.5070493  -10.53781515\n",
      "  -8.92970202 -11.24707499]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1-dones:  [ -3.55056204  -6.98953969  -3.78709321  -7.29610679  -9.41819356\n",
      "  -9.92343177  -5.01213156 -11.07150465  -5.85480241 -11.24707451\n",
      " -10.32671895 -10.02754388  -6.26684928  -8.92970202  -5.01213156\n",
      " -10.02754388 -11.5831928   -4.35691161 -10.45626774  -8.5070493\n",
      "  -9.3382988   -8.88507914  -3.33578656  -8.80016855  -9.36620082\n",
      "  -7.56645329 -10.70312753  -4.35691161  -9.25412217  -4.9415432\n",
      "  -8.80016855 -11.96068226]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1-dones:  [ -5.33384584 -11.74627596 -10.46540338  -9.958474    -9.41819356\n",
      " -10.02754388 -11.85306575 -11.5831928  -10.83245268  -4.82001159\n",
      " -11.07150465 -10.45626774  -8.01827595  -9.80579076  -6.98953969\n",
      " -11.85306575  -9.36620082 -10.53781515 -11.07150465  -9.41819356\n",
      "  -1.26458606  -7.29610679  -5.85394455 -10.3755177   -8.11578082\n",
      "  -8.0479624  -10.02754388 -12.19023078  -4.1011998   -4.35691161\n",
      " -12.19023102  -3.78709321]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1-dones:  [ -9.36620082  -9.41819356  -7.29610679  -9.41819356 -10.73736446\n",
      "  -9.21590195  -4.24191054 -11.07150465  -4.10339946  -6.98953969\n",
      " -10.53781515 -11.24707451  -3.98770153 -10.3755177   -3.55056204\n",
      " -10.3755177   -4.35691161  -5.93351669  -9.92343177 -10.83245268\n",
      " -12.97884258  -6.98953969  -8.0479624  -10.46540338 -11.74627596\n",
      "  -9.10481059 -12.44371289  -9.92343177  -9.21590195  -9.3382988\n",
      "  -5.85394432  -4.26051976]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1-dones:  [ -4.2605197   -9.92343177  -3.55056204 -10.70312753 -11.5831928\n",
      "  -4.35691161  -9.3382988  -11.85306575  -4.67973704  -9.41819356\n",
      "  -8.83537026  -4.35691161 -10.78017974  -8.2146556   -6.98953969\n",
      " -10.21463599  -8.2146556   -3.78709321 -10.00958411  -8.3621067\n",
      " -11.96068226 -10.02754388  -9.14503123 -11.07157232  -1.26458606\n",
      "  -6.82930451  -8.80016855  -5.74569641  -9.36620082 -10.21463599\n",
      " -11.10171285  -4.10339951]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1-dones:  [ -8.88507914  -9.958474    -3.28533841  -1.71241617  -9.92343177\n",
      "  -9.10481059  -6.43353659 -11.5831928   -2.26967535 -11.01360447\n",
      "  -7.56645329 -12.97884258  -9.25412217  -9.92343177  -8.3621067\n",
      " -10.21463599  -4.67973704  -8.5070493   -3.98770153  -5.85394455\n",
      "  -3.28533841 -10.57830419  -9.41819356  -8.2146556   -3.55056204\n",
      " -12.48619483  -9.14503123  -9.958474   -12.97884258  -9.3382988\n",
      "  -5.93351657  -9.80579076]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1-dones:  [ -9.958474   -11.10171285  -9.80579076  -9.25412217  -6.39225821\n",
      "  -3.55056204  -8.62654306  -9.41819356  -9.41819356  -3.26401339\n",
      " -10.70312753  -3.33578656  -5.25945637  -8.01967294  -4.82001159\n",
      " -11.01360447  -5.74569641 -10.70312753 -11.10171285  -8.80016855\n",
      " -13.17733581  -8.03150873  -9.92343177  -9.92343177  -8.2146556\n",
      "  -8.62654306  -8.83537026  -9.14503123  -2.14868783 -11.96068226\n",
      "  -8.80016855  -6.26684904]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1-dones:  [ -4.35691161 -11.85306575  -9.21590195  -2.19874094  -8.01827595\n",
      "  -4.67973704  -9.10481059 -12.48619483  -9.21590195  -1.26458606\n",
      "  -5.85394455 -11.10171285  -6.39225821  -6.26684928  -8.83537026\n",
      "  -7.29610679  -6.09179024  -9.41819356  -4.67973704 -10.53781515\n",
      "  -3.78709321  -9.41819356  -8.5070493  -10.71955508 -10.83245268\n",
      "  -8.03150873  -2.26967535 -11.24707451 -11.96220689 -13.17733581\n",
      " -11.74627596 -12.97884258]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1-dones:  [-11.96220689  -3.55056204  -6.82930451 -10.32671895  -9.41819356\n",
      "  -4.84286142  -9.41819356 -10.46540338 -12.44371289 -10.71955508\n",
      "  -9.3382988  -12.19023078  -5.74569641  -8.03150873  -4.84286142\n",
      "  -7.29610679  -4.1011998   -8.62654306 -10.32671895  -4.1011998\n",
      " -11.5831928  -10.46540338  -1.71241617 -10.3755177   -3.28533841\n",
      " -11.5831928   -9.958474   -10.57830419 -11.85306575 -10.53781515\n",
      "  -8.62654354 -12.44371265]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1-dones:  [ -9.10481059  -9.21590195  -3.26401339  -6.98953969  -4.1011998\n",
      "  -8.03150873  -8.11578082  -9.41819356  -4.24191054  -3.84782821\n",
      "  -5.33384584  -3.84782821 -10.3755177   -8.88507914  -5.74569641\n",
      "  -6.98953969 -11.5831928  -11.96068226  -1.71241617  -2.26967535\n",
      "  -8.11578082 -10.53781515 -10.73736446 -10.73736446  -3.78709321\n",
      "  -6.98953969  -8.83537026  -3.98770153  -8.3621067   -4.35691161\n",
      "  -3.28533817  -1.71241623]\n",
      "DONES:  [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.8/contextlib.py:131\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen\u001b[39m.\u001b[39;49mthrow(\u001b[39mtype\u001b[39;49m, value, traceback)\n\u001b[1;32m    132\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    133\u001b[0m     \u001b[39m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[39m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    135\u001b[0m     \u001b[39m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/c_api_util.py:227\u001b[0m, in \u001b[0;36mtf_buffer\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m   \u001b[39myield\u001b[39;00m buf\n\u001b[1;32m    228\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:2698\u001b[0m, in \u001b[0;36mOperation.get_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2697\u001b[0m \u001b[39mwith\u001b[39;00m c_api_util\u001b[39m.\u001b[39mtf_buffer() \u001b[39mas\u001b[39;00m buf:\n\u001b[0;32m-> 2698\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39;49mTF_OperationGetAttrValueProto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_c_op, name, buf)\n\u001b[1;32m   2699\u001b[0m   data \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_GetBuffer(buf)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'TensorSliceDataset' has no attr named '_read_only_resource_inputs'.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mDONES: \u001b[39m\u001b[39m\"\u001b[39m,dones)\n\u001b[1;32m     50\u001b[0m \u001b[39m# Compute the target Q-values based on the Bellman equation\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m target_Q \u001b[39m=\u001b[39m rewards \u001b[39m+\u001b[39m discount_factor \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mamax(agent\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(next_states), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m dones)\n\u001b[1;32m     53\u001b[0m \u001b[39m# Create a mask to zero out the Q-values for terminal states\u001b[39;00m\n\u001b[1;32m     54\u001b[0m target_Q \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m dones)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py:2349\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2340\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m   2341\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   2342\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2343\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2346\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m   2347\u001b[0m         )\n\u001b[0;32m-> 2349\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[1;32m   2350\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   2351\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2352\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[1;32m   2353\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2354\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   2355\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   2356\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   2357\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   2358\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2359\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution,\n\u001b[1;32m   2360\u001b[0m )\n\u001b[1;32m   2362\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2363\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/data_adapter.py:1583\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1581\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1582\u001b[0m     \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1583\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/data_adapter.py:1260\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1257\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[1;32m   1259\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1260\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   1261\u001b[0m     x,\n\u001b[1;32m   1262\u001b[0m     y,\n\u001b[1;32m   1263\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   1264\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   1265\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   1266\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1267\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   1268\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1269\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1270\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1271\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   1272\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m   1273\u001b[0m )\n\u001b[1;32m   1275\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   1277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/data_adapter.py:346\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m         flat_dataset \u001b[39m=\u001b[39m flat_dataset\u001b[39m.\u001b[39mshuffle(\u001b[39m1024\u001b[39m)\u001b[39m.\u001b[39mrepeat(epochs)\n\u001b[1;32m    344\u001b[0m     \u001b[39mreturn\u001b[39;00m flat_dataset\n\u001b[0;32m--> 346\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mflat_map(slice_batch_indices)\n\u001b[1;32m    348\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[1;32m    350\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py:2285\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[0;34m(self, map_func, name)\u001b[0m\n\u001b[1;32m   2281\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops -> flat_map_op ->\u001b[39;00m\n\u001b[1;32m   2282\u001b[0m \u001b[39m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2283\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2284\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m flat_map_op\n\u001b[0;32m-> 2285\u001b[0m \u001b[39mreturn\u001b[39;00m flat_map_op\u001b[39m.\u001b[39;49m_flat_map(\u001b[39mself\u001b[39;49m, map_func, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/flat_map_op.py:24\u001b[0m, in \u001b[0;36m_flat_map\u001b[0;34m(input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_flat_map\u001b[39m(input_dataset, map_func, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=unused-private-name\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m   \u001b[39mreturn\u001b[39;00m _FlatMapDataset(input_dataset, map_func, name)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/flat_map_op.py:33\u001b[0m, in \u001b[0;36m_FlatMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, input_dataset, map_func, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[0;32m---> 33\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m structured_function\u001b[39m.\u001b[39;49mStructuredFunctionWrapper(\n\u001b[1;32m     34\u001b[0m       map_func, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(), dataset\u001b[39m=\u001b[39;49minput_dataset)\n\u001b[1;32m     35\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure, dataset_ops\u001b[39m.\u001b[39mDatasetSpec):\n\u001b[1;32m     36\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     37\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mdataset_ops\u001b[39m.\u001b[39mget_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure)\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/structured_function.py:261\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    255\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    256\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    257\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    259\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[0;32m--> 261\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[1;32m    262\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[1;32m    263\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:232\u001b[0m, in \u001b[0;36mTracingCompiler.get_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    224\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m \n\u001b[1;32m    226\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39m      `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 232\u001b[0m   concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[1;32m    233\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    234\u001b[0m   concrete_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    235\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:202\u001b[0m, in \u001b[0;36mTracingCompiler._get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mmake_canonicalized_monomorphic_type(args, kwargs)\n\u001b[1;32m    201\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m--> 202\u001b[0m   concrete_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_concrete_function(args, kwargs)\n\u001b[1;32m    203\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    204\u001b[0m   concrete_function\u001b[39m.\u001b[39m_arg_keywords \u001b[39m=\u001b[39m []  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:166\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_concrete_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m   args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_signature\n\u001b[1;32m    164\u001b[0m   kwargs \u001b[39m=\u001b[39m {}\n\u001b[0;32m--> 166\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:396\u001b[0m, in \u001b[0;36mTracingCompiler._maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    393\u001b[0m   args \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39margs\n\u001b[1;32m    394\u001b[0m kwargs \u001b[39m=\u001b[39m placeholder_bound_args\u001b[39m.\u001b[39mkwargs\n\u001b[0;32m--> 396\u001b[0m concrete_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_concrete_function(\n\u001b[1;32m    397\u001b[0m     args, kwargs, func_graph)\n\u001b[1;32m    399\u001b[0m \u001b[39m# TODO(b/263520817): Remove access to private attribute.\u001b[39;00m\n\u001b[1;32m    400\u001b[0m graph_capture_container \u001b[39m=\u001b[39m concrete_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39m_function_captures  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:300\u001b[0m, in \u001b[0;36mTracingCompiler._create_concrete_function\u001b[0;34m(self, args, kwargs, func_graph)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m   arg_names \u001b[39m=\u001b[39m base_arg_names\n\u001b[1;32m    299\u001b[0m concrete_function \u001b[39m=\u001b[39m monomorphic_function\u001b[39m.\u001b[39mConcreteFunction(\n\u001b[0;32m--> 300\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[1;32m    301\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m    302\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[1;32m    303\u001b[0m         args,\n\u001b[1;32m    304\u001b[0m         kwargs,\n\u001b[1;32m    305\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    306\u001b[0m         func_graph\u001b[39m=\u001b[39;49mfunc_graph,\n\u001b[1;32m    307\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[1;32m    308\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[1;32m    309\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[1;32m    310\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value,\n\u001b[1;32m    311\u001b[0m         create_placeholders\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m    312\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[1;32m    313\u001b[0m     spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[1;32m    314\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[1;32m    315\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[1;32m    316\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[1;32m    317\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    319\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py:1266\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1260\u001b[0m   \u001b[39m# Returning a closed-over tensor does not trigger convert_to_tensor.\u001b[39;00m\n\u001b[1;32m   1261\u001b[0m   func_graph\u001b[39m.\u001b[39moutputs\u001b[39m.\u001b[39mextend(\n\u001b[1;32m   1262\u001b[0m       func_graph\u001b[39m.\u001b[39mcapture(x)\n\u001b[1;32m   1263\u001b[0m       \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m flatten(func_graph\u001b[39m.\u001b[39mstructured_outputs)\n\u001b[1;32m   1264\u001b[0m       \u001b[39mif\u001b[39;00m x \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 1266\u001b[0m   func_graph\u001b[39m.\u001b[39mvariables \u001b[39m=\u001b[39m variables\n\u001b[1;32m   1268\u001b[0m \u001b[39mif\u001b[39;00m add_control_dependencies:\n\u001b[1;32m   1269\u001b[0m   func_graph\u001b[39m.\u001b[39mcontrol_outputs\u001b[39m.\u001b[39mextend(deps_control_manager\u001b[39m.\u001b[39mops_which_must_run)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/auto_control_deps.py:465\u001b[0m, in \u001b[0;36mAutomaticControlDependencies.__exit__\u001b[0;34m(self, unused_type, unused_value, unused_traceback)\u001b[0m\n\u001b[1;32m    462\u001b[0m resource_inputs \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[1;32m    463\u001b[0m \u001b[39m# Check for any resource inputs. If we find any, we update control_inputs\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[39m# and last_write_to_resource.\u001b[39;00m\n\u001b[0;32m--> 465\u001b[0m \u001b[39mfor\u001b[39;00m inp, resource_type \u001b[39min\u001b[39;00m _get_resource_inputs(op):\n\u001b[1;32m    466\u001b[0m   is_read \u001b[39m=\u001b[39m resource_type \u001b[39m==\u001b[39m ResourceType\u001b[39m.\u001b[39mREAD_ONLY\n\u001b[1;32m    467\u001b[0m   input_id \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mtensor_id(inp)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/auto_control_deps.py:663\u001b[0m, in \u001b[0;36m_get_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_resource_inputs\u001b[39m(op):\n\u001b[1;32m    662\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Returns an iterable of resources touched by this `op`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m   reads, writes \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mget_read_write_resource_inputs(op)\n\u001b[1;32m    664\u001b[0m   saturated \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m   \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m saturated:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/auto_control_deps_utils.py:105\u001b[0m, in \u001b[0;36mget_read_write_resource_inputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[39mreturn\u001b[39;00m (reads, writes)\n\u001b[1;32m    104\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m   read_only_input_indices \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39;49mget_attr(READ_ONLY_RESOURCE_INPUTS_ATTR)\n\u001b[1;32m    106\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m   \u001b[39m# Attr was not set. Add all resource inputs to `writes` and return.\u001b[39;00m\n\u001b[1;32m    108\u001b[0m   writes\u001b[39m.\u001b[39mupdate(t \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m op\u001b[39m.\u001b[39minputs \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mresource)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py:2699\u001b[0m, in \u001b[0;36mOperation.get_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2697\u001b[0m   \u001b[39mwith\u001b[39;00m c_api_util\u001b[39m.\u001b[39mtf_buffer() \u001b[39mas\u001b[39;00m buf:\n\u001b[1;32m   2698\u001b[0m     pywrap_tf_session\u001b[39m.\u001b[39mTF_OperationGetAttrValueProto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op, name, buf)\n\u001b[0;32m-> 2699\u001b[0m     data \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39mTF_GetBuffer(buf)\n\u001b[1;32m   2700\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   2701\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[1;32m   2702\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[0;32m/usr/lib/python3.8/contextlib.py:159\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[39mraise\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39m# only re-raise if it's *not* the exception that was\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[39m# passed to throw(), because __exit__() must not raise\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[39m# Python 2, where old-style class exceptions are not caught\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[39m# by 'except BaseException'.\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m value:\n\u001b[1;32m    160\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epsilon = epsilon_start\n",
    "for episode in range(num_episodes):\n",
    "    current_state = np.random.rand(2)  # Initialize the current state randomly\n",
    "    goal_state = np.random.rand(2)     # Initialize the goal state randomly\n",
    "\n",
    "    total_reward = 0\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        # Epsilon-greedy action selection\n",
    "        action = agent.select_action(np.concatenate([current_state, goal_state]), epsilon)\n",
    "\n",
    "        # Simulate the action and observe the next state and reward\n",
    "        next_state = current_state.copy()  # For simplicity, we assume the agent moves by one step\n",
    "        if action == 0:\n",
    "            next_state[1] += 1  # Move up\n",
    "        elif action == 1:\n",
    "            next_state[1] -= 1  # Move down\n",
    "        elif action == 2:\n",
    "            next_state[0] -= 1  # Move left\n",
    "        else:\n",
    "            next_state[0] += 1  # Move right\n",
    "\n",
    "        reward = get_reward(current_state, goal_state)\n",
    "\n",
    "        # Store the experience in the replay buffer\n",
    "        replay_buffer.append({\n",
    "            'state': np.concatenate([current_state, goal_state]),\n",
    "            'action': action,\n",
    "            'reward': reward,\n",
    "            'next_state': np.concatenate([next_state, goal_state]),\n",
    "            'done': done\n",
    "        })\n",
    "\n",
    "        total_reward += reward\n",
    "        current_state = next_state\n",
    "\n",
    "        if len(replay_buffer) >= batch_size:\n",
    "            # Sample a mini-batch from the replay buffer\n",
    "            mini_batch = sample_mini_batch_from_replay_buffer(replay_buffer, batch_size)\n",
    "\n",
    "            states = np.array([experience['state'] for experience in mini_batch])\n",
    "            actions = np.array([experience['action'] for experience in mini_batch])\n",
    "            rewards = np.array([experience['reward'] for experience in mini_batch])\n",
    "            next_states = np.array([experience['next_state'] for experience in mini_batch])\n",
    "            dones = np.array([experience['done'] for experience in mini_batch])\n",
    "            print(\"DONES: \",dones)\n",
    "\n",
    "            # Compute the target Q-values based on the Bellman equation\n",
    "            target_Q = rewards + discount_factor * np.amax(agent.model.predict(next_states), axis=1) * (1 - dones)\n",
    "\n",
    "            # Create a mask to zero out the Q-values for terminal states\n",
    "            target_Q *= (1 - dones)\n",
    "            print(\"1-dones: \", target_Q)\n",
    "\n",
    "    # Decay epsilon for epsilon-greedy exploration\n",
    "    epsilon = max(epsilon_end, epsilon_start - episode / epsilon_decay_steps)\n",
    "\n",
    "    print(f\"Episode {episode}: Total Reward = {total_reward}\")\n",
    "\n",
    "# After training, you can use the trained model for making predictions:\n",
    "# goal_state = np.array([goal_x, goal_y])  # Set the goal state for testing\n",
    "# current_state = np.array([start_x, start_y])  # Set the current state for testing\n",
    "# action = agent.select_action(np.concatenate([current_state, goal_state]), epsilon=0.0)\n",
    "# print(f\"Selected Action: {action}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(1-True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
